{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ac1de78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "\n",
    "def download_data(url,filename):    #download file as data\n",
    "    result = requests.get(url)\n",
    "    result.raise_for_status()\n",
    "    with open(filename,'wb') as FILE:\n",
    "        for chunk in result.iter_content(102400):\n",
    "            FILE.write(chunk)\n",
    "            \n",
    "url01 = 'https://www.csie.ntu.edu.tw/~htlin/mooc/datasets/mltech/hw4_nnet_train.dat'\n",
    "url02 = 'https://www.csie.ntu.edu.tw/~htlin/mooc/datasets/mltech/hw4_nnet_test.dat'\n",
    "download_data(url01, 'hw4_nnet_train.txt')\n",
    "download_data(url02, 'hw4_nnet_test.txt')\n",
    "    \n",
    "    \n",
    "def readout(filename):\n",
    "    with open(filename,'r') as FILE:\n",
    "        n, Dx, Dy = 0 ,[], []\n",
    "        \n",
    "        for chunk in FILE:\n",
    "            X= chunk.split()   #split the line into a list of string\n",
    "            X= [ float(X[j]) for j in range(len(X)) ]  #convert the string to numbers   \n",
    "#            X.insert(0,1)                #insert a constant as bias or as threshold\n",
    "            Dx.append(X[0:len(X)-1])     #gather all data ## index len(X)-1 will not be included here\n",
    "            Dy.append(X[len(X)-1])       #index len(X)-1 only\n",
    "            n=n+1\n",
    "        x = np.array(Dx)  #change list X into array x\n",
    "        y = np.array(Dy)\n",
    "#    print(x,n)            \n",
    "    return x,y,n        \n",
    "\n",
    "\n",
    "def eout(w,testx,testy):\n",
    "    err = []\n",
    "    yhat = [np.dot(w,testx[i]) for i in range(testn)]\n",
    "\n",
    "    for a,b in zip(yhat,testy):\n",
    "        if a*b<=0:\n",
    "            err.append(1)\n",
    "        else:\n",
    "            err.append(0)\n",
    "    eout = sum(err) /testn\n",
    "    return eout\n",
    "\n",
    "\n",
    "trainx, trainy, trainn = readout('hw4_nnet_train.txt')\n",
    "testx, testy, testn    = readout('hw4_nnet_test.txt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0165a5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M = 1 Eout = 0.32503200000000027 time consumed: 1691.8870646953583\n",
      "M = 6 Eout = 0.038711999999999906 time consumed: 3444.949547767639\n",
      "M = 11 Eout = 0.03963999999999993 time consumed: 5051.830329656601\n",
      "M = 16 Eout = 0.038711999999999934 time consumed: 6889.550478935242\n",
      "M = 21 Eout = 0.03799199999999987 time consumed: 9046.050089120865\n"
     ]
    }
   ],
   "source": [
    "#11 Back propagation\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "def initw(n,m):\n",
    "#    w = [[random.uniform(-r,r) for i in range(m)] for i in range(n+1)]  #vector W 有M個 --- dim of w1: n+1*m matrix\n",
    "    w = np.random.rand(n+1, m)\n",
    "    w = (w-0.5)*2*r\n",
    "    return np.array(w)\n",
    "\n",
    "def updatew(w,x,delta):          # Gradient descent: w = w - eta*x(l-1)[i]*delta(l)[j]\n",
    "    for i in range(w.shape[0]):\n",
    "        for j in range(w.shape[1]):\n",
    "            w[i,j] = w[i,j]-eta*x[i]*delta[j]\n",
    "    return w\n",
    "    \n",
    "def err(w1,w2,x,y,n):\n",
    "    x = np.insert(x,0,np.full(n,1),axis=1)\n",
    "    x1 = np.tanh(w1.T.dot(x.T))\n",
    "    x1 = np.insert(x1,0,np.full(n,1),axis=0)\n",
    "    yhat = np.tanh(w2.T.dot(x1))\n",
    "    er = y*yhat<0\n",
    "    eout = er.sum()/n\n",
    "    \n",
    "\n",
    "    return eout\n",
    "  \n",
    "\n",
    "m = [1,6,11,16,21]\n",
    "t = 500        #run t experiments\n",
    "T = 50000    #run T iteratios per experiment\n",
    "eta = 0.1\n",
    "r = 0.1\n",
    "d = len(trainx[0])\n",
    "N = trainn\n",
    "\n",
    "\n",
    "\n",
    "for M in m:\n",
    "    start = time.time()   \n",
    "    nndim = [d,M,1]   #d-M-1\n",
    "    Err = 0\n",
    "    n0 = nndim[0]       #numbers of x0\n",
    "    n1 = nndim[1]       #numbers of hidden neurons\n",
    "    n2 = nndim[2]       #numbers of output neuron\n",
    " \n",
    "    for times in range(t):\n",
    "        w1 = initw(nndim[0],nndim[1])  \n",
    "        w2 = initw(nndim[1],nndim[2])\n",
    "\n",
    "\n",
    "        for iteration in range(T):\n",
    "            randomn = random.randint(0,N-1)\n",
    "            x0 = np.insert(trainx[randomn],0,1)  #dimension of d+1\n",
    "            x0 = np.reshape(x0,(-1,1))           #One shape dimension can be -1, inferred from the length of the array and remaining dim\n",
    "            s1 = w1.T.dot(x0)\n",
    "            x1 = np.tanh(s1)\n",
    "\n",
    "            x1 = np.insert(x1,0,1,axis=0)  #dimension of M+1\n",
    "            s2 = w2.T.dot(x1)\n",
    "            x2 = np.tanh(s2)\n",
    "\n",
    "            delta2 = (-8)*(trainy[randomn]-np.tanh(s2))/(np.exp(s2)+np.exp(-s2))\n",
    "            delta1 = delta2*w2[1:]*4/(np.exp(s1)+np.exp(-s1))\n",
    "\n",
    "            w2 = updatew(w2,x1,delta2)\n",
    "            w1 = updatew(w1,x0,delta1)\n",
    "\n",
    "        Err = Err+err(w1,w2,testx,testy,testn)\n",
    "#        print(Err/(times+1))\n",
    "        \n",
    "    Eout = Err/t\n",
    "    \n",
    "    end = time.time()\n",
    "    print('M =',M,'Eout =',Eout,'time consumed:',end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89a01f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M = 3 r = 0.0 eta = 0.1 Eout = 0.4914880000000004 time consumed: 2516.1669857501984\n",
      "M = 3 r = 0.001 eta = 0.1 Eout = 0.03891999999999989 time consumed: 2496.7293293476105\n",
      "M = 3 r = 0.1 eta = 0.1 Eout = 0.03855199999999991 time consumed: 2531.825089454651\n",
      "M = 3 r = 10.0 eta = 0.1 Eout = 0.1885519999999999 time consumed: 2547.2259657382965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paes20705\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:40: RuntimeWarning: overflow encountered in exp\n",
      "C:\\Users\\paes20705\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:39: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M = 3 r = 1000.0 eta = 0.1 Eout = 0.493976 time consumed: 2681.218108892441\n"
     ]
    }
   ],
   "source": [
    "#12 Back propagation with diff r\n",
    "\n",
    "\n",
    "#m = [1,6,11,16,21]\n",
    "M = 3\n",
    "t = 500        #run t experiments\n",
    "T = 50000    #run T iteratios per experiment\n",
    "eta = 0.1\n",
    "R = np.array([0,0.001,0.1,10,1000])\n",
    "d = len(trainx[0])\n",
    "N = trainn\n",
    "\n",
    "\n",
    "\n",
    "for r in R:\n",
    "    start = time.time()   \n",
    "    nndim = [d,M,1]   #d-M-1\n",
    "    Err = 0\n",
    "    n0 = nndim[0]       #numbers of x0\n",
    "    n1 = nndim[1]       #numbers of hidden neurons\n",
    "    n2 = nndim[2]       #numbers of output neuron\n",
    " \n",
    "    for times in range(t):\n",
    "        w1 = initw(nndim[0],nndim[1])  \n",
    "        w2 = initw(nndim[1],nndim[2])\n",
    "\n",
    "\n",
    "        for iteration in range(T):\n",
    "            randomn = random.randint(0,N-1)\n",
    "            x0 = np.insert(trainx[randomn],0,1)  #dimension of d+1\n",
    "            x0 = np.reshape(x0,(-1,1))           #One shape dimension can be -1, inferred from the length of the array and remaining dim\n",
    "            s1 = w1.T.dot(x0)\n",
    "            x1 = np.tanh(s1)\n",
    "\n",
    "            x1 = np.insert(x1,0,1,axis=0)  #dimension of M+1\n",
    "            s2 = w2.T.dot(x1)\n",
    "            x2 = np.tanh(s2)\n",
    "\n",
    "            delta2 = (-8)*(trainy[randomn]-np.tanh(s2))/(np.exp(s2)+np.exp(-s2))\n",
    "            delta1 = delta2*w2[1:]*4/(np.exp(s1)+np.exp(-s1))\n",
    "\n",
    "            w2 = updatew(w2,x1,delta2)\n",
    "            w1 = updatew(w1,x0,delta1)\n",
    "\n",
    "        Err = Err+err(w1,w2,testx,testy,testn)\n",
    "#        print(Err/(times+1))\n",
    "        \n",
    "    Eout = Err/t\n",
    "    \n",
    "    end = time.time()\n",
    "    print('M =',M,'r =',r,'eta =',eta,'Eout =',Eout,'time consumed:',end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26e658b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M = 3 r = 0.1 eta = 0.001 Eout = 0.036415999999999886 time consumed: 2627.4103178977966\n",
      "M = 3 r = 0.1 eta = 0.01 Eout = 0.03495199999999988 time consumed: 2651.647789955139\n",
      "M = 3 r = 0.1 eta = 0.1 Eout = 0.03839199999999985 time consumed: 3090.625109910965\n",
      "M = 3 r = 0.1 eta = 1 Eout = 0.49131200000000014 time consumed: 2531.1620848178864\n",
      "M = 3 r = 0.1 eta = 10 Eout = 0.49652800000000036 time consumed: 2531.8207507133484\n"
     ]
    }
   ],
   "source": [
    "#13 Back propagation with diff eta\n",
    "\n",
    "#m = [1,6,11,16,21]\n",
    "\n",
    "t = 500        #run t experiments\n",
    "T = 50000    #run T iteratios per experiment\n",
    "M = 3\n",
    "Eta = [0.001,0.01,0.1,1,10]\n",
    "r = 0.1\n",
    "d = len(trainx[0])\n",
    "N = trainn\n",
    "\n",
    "\n",
    "\n",
    "for eta in Eta:\n",
    "    start = time.time()   \n",
    "    nndim = [d,M,1]   #d-M-1\n",
    "    Err = 0\n",
    "    n0 = nndim[0]       #numbers of x0\n",
    "    n1 = nndim[1]       #numbers of hidden neurons\n",
    "    n2 = nndim[2]       #numbers of output neuron\n",
    " \n",
    "    for times in range(t):\n",
    "        w1 = initw(nndim[0],nndim[1])  \n",
    "        w2 = initw(nndim[1],nndim[2])\n",
    "\n",
    "\n",
    "        for iteration in range(T):\n",
    "            randomn = random.randint(0,N-1)\n",
    "            x0 = np.insert(trainx[randomn],0,1)  #dimension of d+1\n",
    "            x0 = np.reshape(x0,(-1,1))           #One shape dimension can be -1, inferred from the length of the array and remaining dim\n",
    "            s1 = w1.T.dot(x0)\n",
    "            x1 = np.tanh(s1)\n",
    "\n",
    "            x1 = np.insert(x1,0,1,axis=0)  #dimension of M+1\n",
    "            s2 = w2.T.dot(x1)\n",
    "            x2 = np.tanh(s2)\n",
    "\n",
    "            delta2 = (-8)*(trainy[randomn]-np.tanh(s2))/(np.exp(s2)+np.exp(-s2))\n",
    "            delta1 = delta2*w2[1:]*4/(np.exp(s1)+np.exp(-s1))\n",
    "\n",
    "            w2 = updatew(w2,x1,delta2)\n",
    "            w1 = updatew(w1,x0,delta1)\n",
    "\n",
    "        Err = Err+err(w1,w2,testx,testy,testn)\n",
    "#        print(Err/(times+1))\n",
    "        \n",
    "    Eout = Err/t\n",
    "    \n",
    "    end = time.time()\n",
    "    print('M =',M,'r =',r,'eta =',eta,'Eout =',Eout,'time consumed:',end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b53508bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.064\n",
      "0.044\n",
      "0.056\n",
      "0.032\n",
      "0.044\n",
      "0.048\n",
      "0.044\n",
      "0.056\n",
      "0.048\n",
      "0.052\n",
      "0.052\n",
      "0.048\n",
      "0.044\n",
      "0.048\n",
      "0.036\n",
      "0.032\n",
      "0.056\n",
      "0.044\n",
      "0.052\n",
      "0.044\n",
      "0.04\n",
      "0.072\n",
      "0.056\n",
      "0.04\n",
      "0.056\n",
      "0.068\n",
      "0.036\n",
      "0.056\n",
      "0.052\n",
      "0.044\n",
      "0.032\n",
      "0.056\n",
      "0.052\n",
      "0.036\n",
      "0.056\n",
      "0.06\n",
      "0.044\n",
      "0.048\n",
      "0.052\n",
      "0.052\n",
      "0.068\n",
      "0.056\n",
      "0.036\n",
      "0.044\n",
      "0.032\n",
      "0.048\n",
      "0.048\n",
      "0.032\n",
      "0.036\n",
      "0.048\n",
      "0.048\n",
      "0.052\n",
      "0.052\n",
      "0.068\n",
      "0.048\n",
      "0.04\n",
      "0.044\n",
      "0.052\n",
      "0.048\n",
      "0.052\n",
      "0.056\n",
      "0.056\n",
      "0.036\n",
      "0.048\n",
      "0.04\n",
      "0.032\n",
      "0.068\n",
      "0.036\n",
      "0.044\n",
      "0.04\n",
      "0.048\n",
      "0.052\n",
      "0.036\n",
      "0.048\n",
      "0.04\n",
      "0.048\n",
      "0.036\n",
      "0.052\n",
      "0.068\n",
      "0.048\n",
      "0.036\n",
      "0.056\n",
      "0.04\n",
      "0.064\n",
      "0.06\n",
      "0.036\n",
      "0.048\n",
      "0.052\n",
      "0.04\n",
      "0.044\n",
      "0.044\n",
      "0.044\n",
      "0.048\n",
      "0.06\n",
      "0.044\n",
      "0.032\n",
      "0.044\n",
      "0.044\n",
      "0.056\n",
      "0.044\n",
      "0.044\n",
      "0.04\n",
      "0.068\n",
      "0.056\n",
      "0.04\n",
      "0.056\n",
      "0.044\n",
      "0.056\n",
      "0.052\n",
      "0.056\n",
      "0.048\n",
      "0.044\n",
      "0.04\n",
      "0.044\n",
      "0.044\n",
      "0.036\n",
      "0.056\n",
      "0.044\n",
      "0.048\n",
      "0.048\n",
      "0.056\n",
      "0.04\n",
      "0.068\n",
      "0.044\n",
      "0.052\n",
      "0.044\n",
      "0.036\n",
      "0.056\n",
      "0.04\n",
      "0.04\n",
      "0.044\n",
      "0.044\n",
      "0.036\n",
      "0.04\n",
      "0.048\n",
      "0.056\n",
      "0.036\n",
      "0.036\n",
      "0.036\n",
      "0.06\n",
      "0.048\n",
      "0.056\n",
      "0.056\n",
      "0.044\n",
      "0.064\n",
      "0.032\n",
      "0.064\n",
      "0.048\n",
      "0.036\n",
      "0.048\n",
      "0.04\n",
      "0.052\n",
      "0.056\n",
      "0.064\n",
      "0.048\n",
      "0.044\n",
      "0.036\n",
      "0.036\n",
      "0.04\n",
      "0.048\n",
      "0.048\n",
      "0.036\n",
      "0.04\n",
      "0.04\n",
      "0.068\n",
      "0.044\n",
      "0.044\n",
      "0.036\n",
      "0.048\n",
      "0.044\n",
      "0.04\n",
      "0.04\n",
      "0.052\n",
      "0.048\n",
      "0.072\n",
      "0.056\n",
      "0.072\n",
      "0.04\n",
      "0.044\n",
      "0.056\n",
      "0.048\n",
      "0.044\n",
      "0.064\n",
      "0.056\n",
      "0.064\n",
      "0.036\n",
      "0.04\n",
      "0.056\n",
      "0.04\n",
      "0.036\n",
      "0.04\n",
      "0.052\n",
      "0.032\n",
      "0.068\n",
      "0.052\n",
      "0.056\n",
      "0.052\n",
      "0.068\n",
      "0.064\n",
      "0.056\n",
      "0.056\n",
      "0.036\n",
      "0.048\n",
      "0.052\n",
      "0.052\n",
      "0.056\n",
      "0.052\n",
      "0.044\n",
      "0.052\n",
      "0.044\n",
      "0.052\n",
      "0.036\n",
      "0.056\n",
      "0.032\n",
      "0.052\n",
      "0.064\n",
      "0.044\n",
      "0.048\n",
      "0.072\n",
      "0.044\n",
      "0.052\n",
      "0.04\n",
      "0.056\n",
      "0.036\n",
      "0.064\n",
      "0.04\n",
      "0.052\n",
      "0.056\n",
      "0.06\n",
      "0.064\n",
      "0.056\n",
      "0.068\n",
      "0.044\n",
      "0.048\n",
      "0.04\n",
      "0.052\n",
      "0.052\n",
      "0.052\n",
      "0.044\n",
      "0.052\n",
      "0.048\n",
      "0.052\n",
      "0.04\n",
      "0.04\n",
      "0.052\n",
      "0.056\n",
      "0.056\n",
      "0.048\n",
      "0.048\n",
      "0.04\n",
      "0.052\n",
      "0.06\n",
      "0.068\n",
      "0.052\n",
      "0.052\n",
      "0.056\n",
      "0.064\n",
      "0.056\n",
      "0.052\n",
      "0.056\n",
      "0.052\n",
      "0.056\n",
      "0.048\n",
      "0.044\n",
      "0.036\n",
      "0.056\n",
      "0.044\n",
      "0.044\n",
      "0.052\n",
      "0.044\n",
      "0.044\n",
      "0.052\n",
      "0.036\n",
      "0.052\n",
      "0.044\n",
      "0.048\n",
      "0.056\n",
      "0.04\n",
      "0.048\n",
      "0.048\n",
      "0.072\n",
      "0.052\n",
      "0.048\n",
      "0.032\n",
      "0.044\n",
      "0.048\n",
      "0.036\n",
      "0.036\n",
      "0.04\n",
      "0.044\n",
      "0.064\n",
      "0.04\n",
      "0.048\n",
      "0.044\n",
      "0.048\n",
      "0.052\n",
      "0.044\n",
      "0.052\n",
      "0.056\n",
      "0.048\n",
      "0.048\n",
      "0.044\n",
      "0.044\n",
      "0.052\n",
      "0.044\n",
      "0.056\n",
      "0.036\n",
      "0.04\n",
      "0.04\n",
      "0.048\n",
      "0.048\n",
      "0.052\n",
      "0.052\n",
      "0.056\n",
      "0.052\n",
      "0.056\n",
      "0.036\n",
      "0.04\n",
      "0.052\n",
      "0.048\n",
      "0.056\n",
      "0.052\n",
      "0.04\n",
      "0.036\n",
      "0.048\n",
      "0.044\n",
      "0.036\n",
      "0.06\n",
      "0.072\n",
      "0.048\n",
      "0.048\n",
      "0.064\n",
      "0.036\n",
      "0.048\n",
      "0.052\n",
      "0.048\n",
      "0.044\n",
      "0.048\n",
      "0.036\n",
      "0.052\n",
      "0.052\n",
      "0.052\n",
      "0.048\n",
      "0.032\n",
      "0.068\n",
      "0.048\n",
      "0.036\n",
      "0.036\n",
      "0.052\n",
      "0.048\n",
      "0.052\n",
      "0.048\n",
      "0.032\n",
      "0.048\n",
      "0.044\n",
      "0.04\n",
      "0.064\n",
      "0.056\n",
      "0.04\n",
      "0.044\n",
      "0.036\n",
      "0.048\n",
      "0.044\n",
      "0.052\n",
      "0.044\n",
      "0.052\n",
      "0.044\n",
      "0.048\n",
      "0.048\n",
      "0.036\n",
      "0.052\n",
      "0.052\n",
      "0.036\n",
      "0.04\n",
      "0.068\n",
      "0.052\n",
      "0.04\n",
      "0.056\n",
      "0.04\n",
      "0.052\n",
      "0.052\n",
      "0.052\n",
      "0.044\n",
      "0.044\n",
      "0.032\n",
      "0.04\n",
      "0.052\n",
      "0.056\n",
      "0.064\n",
      "0.036\n",
      "0.052\n",
      "0.04\n",
      "0.068\n",
      "0.036\n",
      "0.044\n",
      "0.04\n",
      "0.056\n",
      "0.036\n",
      "0.048\n",
      "0.052\n",
      "0.048\n",
      "0.052\n",
      "0.044\n",
      "0.044\n",
      "0.048\n",
      "0.048\n",
      "0.044\n",
      "0.048\n",
      "0.052\n",
      "0.052\n",
      "0.044\n",
      "0.04\n",
      "0.068\n",
      "0.036\n",
      "0.04\n",
      "0.056\n",
      "0.056\n",
      "0.076\n",
      "0.056\n",
      "0.056\n",
      "0.056\n",
      "0.052\n",
      "0.036\n",
      "0.056\n",
      "0.068\n",
      "0.056\n",
      "0.044\n",
      "0.04\n",
      "0.056\n",
      "0.032\n",
      "0.044\n",
      "0.052\n",
      "0.04\n",
      "0.072\n",
      "0.056\n",
      "0.064\n",
      "0.048\n",
      "0.068\n",
      "0.056\n",
      "0.04\n",
      "0.036\n",
      "0.048\n",
      "0.048\n",
      "0.052\n",
      "0.044\n",
      "0.044\n",
      "0.044\n",
      "0.048\n",
      "0.068\n",
      "0.036\n",
      "0.052\n",
      "0.036\n",
      "0.052\n",
      "0.048\n",
      "0.056\n",
      "0.036\n",
      "0.056\n",
      "0.048\n",
      "0.048\n",
      "0.036\n",
      "0.052\n",
      "0.036\n",
      "0.056\n",
      "0.044\n",
      "0.044\n",
      "0.048\n",
      "0.036\n",
      "0.064\n",
      "0.04\n",
      "0.064\n",
      "0.044\n",
      "0.056\n",
      "0.044\n",
      "0.044\n",
      "0.056\n",
      "0.044\n",
      "0.036\n",
      "0.052\n",
      "0.056\n",
      "0.056\n",
      "0.052\n",
      "0.056\n",
      "0.064\n",
      "0.056\n",
      "0.068\n",
      "0.056\n",
      "0.044\n",
      "0.036\n",
      "0.056\n",
      "0.036\n",
      "0.044\n",
      "0.032\n",
      "0.04\n",
      "0.036\n",
      "0.048\n",
      "0.052\n",
      "0.036\n",
      "0.064\n",
      "0.044\n",
      "0.048\n",
      "M = 8 r = 0.1 eta = 0.01 Eout = 0.0484319999999999 time consumed: 6375.5000722408295\n"
     ]
    }
   ],
   "source": [
    "#14 Back propagation with DNN\n",
    "\n",
    "def initw(n,m):\n",
    "#    w = [[random.uniform(-r,r) for i in range(m)] for i in range(n+1)]  #vector W 有M個 --- dim of w1: n+1*m matrix\n",
    "    w = np.random.rand(n+1, m)\n",
    "    w = (w-0.5)*2*r\n",
    "    return np.array(w)\n",
    "\n",
    "def updatew(w,x,delta):          # Gradient descent: w = w - eta*x(l-1)[i]*delta(l)[j]\n",
    "    for i in range(w.shape[0]):\n",
    "        for j in range(w.shape[1]):\n",
    "            w[i,j] = w[i,j]-eta*x[i]*delta[j]\n",
    "    return w\n",
    "def err(w1,w2,w3,x,y,n):\n",
    "    x = np.insert(x,0,np.full(n,1),axis=1)\n",
    "    x1 = np.tanh(w1.T.dot(x.T))\n",
    "    x1 = np.insert(x1,0,np.full(n,1),axis=0)\n",
    "    x2 = np.tanh(w2.T.dot(x1))\n",
    "    x2 = np.insert(x2,0,np.full(n,1),axis=0)\n",
    "    yhat = np.tanh(w3.T.dot(x2))\n",
    "    er = y*yhat<0\n",
    "    eout = er.sum()/n\n",
    "    \n",
    "    return eout\n",
    "\n",
    "\n",
    "#m = [1,6,11,16,21]\n",
    "\n",
    "t = 500        #run t experiments\n",
    "T = 50000    #run T iteratios per experiment\n",
    "M = 8\n",
    "m = 3\n",
    "eta = 0.01\n",
    "r = 0.1\n",
    "d = len(trainx[0])\n",
    "N = trainn\n",
    "\n",
    "\n",
    "start = time.time()   \n",
    "nndim = [d,M,m,1]   #d-M-1\n",
    "Err = 0\n",
    "\n",
    "\n",
    "for times in range(t):\n",
    "    w1 = initw(nndim[0],nndim[1])  \n",
    "    w2 = initw(nndim[1],nndim[2])\n",
    "    w3 = initw(nndim[2],nndim[3])\n",
    "\n",
    "    for iteration in range(T):\n",
    "        randomn = random.randint(0,N-1)\n",
    "        x0 = np.insert(trainx[randomn],0,1)  #dimension of d+1\n",
    "        x0 = np.reshape(x0,(-1,1))           #One shape dimension can be -1, inferred from the length of the array and remaining dim\n",
    "        s1 = w1.T.dot(x0)\n",
    "        x1 = np.tanh(s1)\n",
    "\n",
    "        x1 = np.insert(x1,0,1,axis=0)  #dimension of 8+1\n",
    "        s2 = w2.T.dot(x1)\n",
    "        x2 = np.tanh(s2)\n",
    "        \n",
    "        x2 = np.insert(x2,0,1,axis=0)  #dimension of 3+1\n",
    "        s3 = w3.T.dot(x2)\n",
    "        x3 = np.tanh(s3)\n",
    "        \n",
    "        delta3 = (-8)*(trainy[randomn]-np.tanh(s3))/(np.exp(s3)+np.exp(-s3))\n",
    "        delta2 = delta3*w3[1:]*4/(np.exp(s2)+np.exp(-s2))\n",
    "        delta1 = w2[1:].dot(delta2)*4/(np.exp(s1)+np.exp(-s1))\n",
    "        \n",
    "        \n",
    "        w3 = updatew(w3,x2,delta3)\n",
    "        w2 = updatew(w2,x1,delta2)\n",
    "        w1 = updatew(w1,x0,delta1)\n",
    "\n",
    "\n",
    "    Err = Err+err(w1,w2,w3,testx,testy,testn)\n",
    "#    print(err(w1,w2,w3,testx,testy,testn))\n",
    "\n",
    "        \n",
    "Eout = Err/t\n",
    "\n",
    "end = time.time()\n",
    "print('M =',M,'r =',r,'eta =',eta,'Eout =',Eout,'time consumed:',end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa177ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
